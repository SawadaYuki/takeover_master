#ABSTRACT
これまでにないほど(unprecedented)の並列処理は、スケーラビリティの限界を明らかにしています。
限られたスケーラビリティの原因を検出するには、正確で自動化された手法が必要です。
まず、ユーザーはアプリケーションのスケーラビリティを理解する上で数多くの課題に直面していると主張します。
膨大な量の実験データを管理し、このデータから有用なトレンドを抽出し、パフォーマンス情報をアプリケーションの設計と調整します。
次に、スケーラビリティ実験データに基本的な統計手法を適用して、このデータ解析問題を自動化するソリューションを提案します。
最後に、いくつかのアプリケーションで運用プロトタイプを評価し、**統計的手法がアプリケーションのスケーラビリティを評価するための効果的な戦略を提供することを示します。**

特に、タスクの数のノンパラメトリックな相関は、通信動作の時間と全体の通信時間との比に比例して、規模の小さい通信動作を識別するための信頼できる尺度を提供する。

#1 INTRODUCTION
間違いなく(Undoubtedly)、並行性のこの新しい、高度な同時並列性(concurrency)は、他のアプリケーションやシステムの特性によって覆われている(be shrouded)かもしれない「並行性のレベルが低いアプリケーションのスケーラビリティの限界」を明らかにする(expose)でしょう。

さらに、単一ノードのパフォーマンスの永続的な(perpetual)向上により、分散アプリケーションにおける通信operationのスケーラビリティの限界が明らかになります(reveal)。

実行時間、スピードアップ、効率[14]などのメトリックは、抽象レベルのスケーラビリティを定量化するのに役立ちますが、ユーザはアプリケーションにおいて、スケーラビリティの低い通信オペレーションに関する精密な(precise)情報を必要とします。
さらに、ユーザーがアプリケーションのスケーラビリティを理解するのに役立つ分析のために、
そのテクノロジは、ユーザーがアプリケーションの設計時に行う決定に関して(in terms of)スケーラビリティ現象(phenomena)を説明できる必要があります。

この目的のために、われわれはよく知られた統計的手法を使用して、アプリケーションにおけるスケーリングの少ない通信operationにユーザーの注意を向ける自動化されたテクニックを提案する。

我々の方法は、複数のアプリケーション実験の結果を示し、**その成長(growth)がタスクの数と正の相関を持つ通信operationを示唆している。**
我々の結果は、いずれの場合も、高度な並列実験中に**アプリケーションの実行時間を支配するように成長する通信オペレーションを迅速に特定できる**ことを示しています。

##1.2 Paper Organization
**セクション2**では、ケーススタディを使用してスケーラビリティ分析を動機づける
これに続いて、**セクション3**では、統計的手法を用いてスケーラビリティデータを分析するアプローチを紹介する。
次に、**セクション4**では、これらの手法を多数のMPIアプリケーションで評価します。

# 2 MOTIVATING EXAMPLE
BTのスケーラビリティを分析するための第一歩として、まず図1に示すように、4タスクから最大225タスクまでのBTのランタイムを集約して示す。

より具体的には、各タスクの時間を通信(Tcomm)、および計算Tcomp(または図1のMPI)に分割します。
各タスク(i)は、T(i,comm)とT(i,comp)をもつ(同時にタスクiの実行時間T(i,app)も作られる)
Taggは、すべてのタスクのプロセッサ時間合計として定義します。
同様に、T(agg,comm)として、すべてのタスクにまたがる通信の合計時間を定義します。

この実験ではクラスBの固定問題サイズを使用していることに留意して、図1は、各実験サイズの集約アプリケーションランタイムの一部としての通信時間の内訳を示しています。

この分析では、この問題サイズでは、最大81個のプロセッサを有効に使用していることがわかります。ただし、この時点で**BTの通信時間が長くなるとアプリケーション時間が長くなります。=>81個のプロセッサ数を超た辺りから通信時間が大きく増加**

注目すべきことに、BTにおけるコミュニケーションの一部は増加しています。 しかし、この解決法はあまりにも粗すぎる(too coarse)ままです。
**すべての通信operationが均等に低下するか、または1つまたは2つの通信操作が通信時間を劇的に増加させるかどうかは不明である。**
次のステップとして、通信時間を操作（例えば、バリア、リダクション、センド）によって分解する。
**多くのMPIパフォーマンス分析ツールは、MPIコールのタイプによってデータをキャプチャし、同じMPIライブラリルーチンに異なるコールサイトを見分けない(distinguish)。**

T（i、op）は、タスクiが通信operationのopタイプに費やした合計時間を提供します。
**図2に、BTの種類別の通信動作の内訳を示す。**
この観点から見ると、私たちはBTの1つのタイプの通信オペレーションについてスケーラビリティ分析を集中することができます：
Wait,Barrier,Waitall,and Comm_split.

81タスク以下まではT(agg,wait)は最大のコンポーネントだったが比較的(relatively)一定である。:
81タスクを超てからT(agg,wait)は通信時間を支配する(dominates)。
**また、Barrier、Waitall、およびComm_splitは、タスクの数が増えるにつれてグループから顕著に(noticeably)出現します(emerge)。**
しかし、現実的には、アプリケーションは複数のコールサイトからこれらの操作を呼び出します。
**最後に、T(agg,wait)を個々のコールサイトに分割しました。**
図3がいくつかの選択コールサイトについて示すのと同様に、すべてのWaitオペレーションが同様に機能するわけではないことが分かったところで、T(i,wait)をT(i,wait,callsite)としてリキャストします。

確かに、4つのウェイトのうちの2つは驚異的な規模であり、他の2つのwait,x_solve.f:71とy_solve.f:70は、はるかに悪化します。

**実際、コールサイトによるこの通信時間の分解は、BTに関するいくつかの興味深い特徴を示している。**
まず、データポイントの多くはかなり騒がしいです。 たとえば、図3のComm_splitデータを参照してください。
図1では、通信時間が着実に増加しても、これらのサンプル点は大きく変動します。
私たちの経験によれば、このノイズは、特に大規模な生産コンピューティングシステムでは一般的です。
第2に、図3の曲線の形状は、図1の通信時間と著しく類似しています。
すべてのコールサイトは、81タスクまで比較的フラットです。

いずれにせよ、この情報が与えられた場合、ユーザは、特に同じ通信オペレーションへの呼び出しが異なる動作をすることを考慮すると、これらのオペレーションのスケールが貧弱な理由について詳細な調査を開始することができる。
**スケーリングが不十分な理由には、負荷バランスの悪さやアルゴリズム設計など、さまざまな原因が考えられます。**
また、すべてのコールサイトからのこの証拠を使用して、ユーザーは同じ通信ルーチンへの呼び出しを比較し、最も病理的な場合を除いて実装問題を排除できます。

#3 STATISTICAL SCALABILITY ANALYSIS

**私たちは、データから有意義な関係を抽出するために統計分析に依存する代替ソリューションを提案します。
私たちのソリューションでは、ユーザーはスケーラビリティ実験の結果を簡単に抽出して、スケールの悪い通信オペレーションを自動的に明らかにすることができます。**

**図4は、統計的スケーラビリティ分析のプロセスを示しています。**
私たちのプロセスは2つの段階で構成されています。
まず、複数のスケーラビリティ実験では、タスクの数、場合によっては問題のサイズが変化します。
各実験では、すべての通信操作のコールサイトに関する特定のタイミング情報を記録します。
ユーザーは各設定で複数の実験を行うことができます。 実際には、これを推奨します。
プロセスの次のステップでは、すべてのスケーラビリティ実験ファイルをマージし、各コールサイトに関するタイミング情報を収集します。
この情報を手にして、**総コール時間に対する各コールサイトの合計時間の比率を計算します。**
次に、この比率と各実験のタスク数をランク付けします。
最後に、我々のプロセスは、ランク付けされた比率とランク付けされたタスク数との間の相関を計算する。
セクション4に示すように、集計時間の非パラメトリック（またはランク）相関は、**規模の小さい通信操作を識別するための正確で安定した予測子を提供することがわかります。**

#3.1 Performance Data Management
第2章で示したスケーラビリティ分析の段階を反映するためにデータを整理します。

この分析では、アプリケーション内のすべてのタスクのすべてのコールサイトに対して、カウント、累積時間、最小時間、および最大時間があると想定しています。

MGからのこの性能データの例を表1に示す。

我々は、この種のデータへの直接的なアクセスを提供するために、**MPIプロファイリング層[9]を使用してソフトウェアツールを構築した。**
さらに、**最初から最後まで各タスク(各プロセス)の実行時間を取得します。**
この情報を使用して、セクション2で示したすべての分析を実行し、スピードアップなどの派生値を計算できます。

**スケーラビリティ分析のために、データを整理するためのいくつかのオプションがあります。**
**1つの方法は、ある実験での各タスクのコールサイト時間を他の実験での同じコールサイト時間と比較することです。**
このオプションには、定義上、実験には異なる数のタスクがあるため、実験を通してコールサイト値をタスクごとに比較することは**意味がないという欠点があります。**
**その結果、コールサイトデータを分析するための2つ目の戦略が選択されました。**
**各テストにおいて、すべてのタスクのコールサイトの値を集約し、他のテストにおいて類似した集計を出す集計と比較します。**
**表2は、3つのBT実験に関する集約コールサイトデータを示す。**

この選択には多くの意味があります。
**まず、時間を集約することで、タスク間の微妙な(subtle)違いを抑え(suppress)、負荷の不均衡を突き止めるある情報を浪費する(squander )かもしれない。**
第2に、この集約は、スケーリングされた問題または固定された問題のサイズに対して異なる結果をもたらします。

**しかし、最終的な分析では生の時間ではなく比を使用してこの差を補う。**

#4.3.1 NAS Parallel Benchmarks
図6は、NASベンチマークのスケーリング結果を示しています。
すべてのNASベンチマークは、固定された問題サイズに制約されている(are constrained)ため、拡張性があります。

他の研究者ら[24]が指摘しているように、これらのベンチマークは、通信オーバヘッドの必然的な(inevitable)増加と縮小しているローカル問題の大きさから苦しみ始める限界までの間、ますます多くのプロセッサを効果的に利用しています。

ベンチマークアプリケーションNAS SPおよびBTは、Navier-Stokes方程式の暗黙的な有限差分離散離散化から概算される方程式系を解く計算流体力学（CFD）アプリケーションを表します。
SPアルゴリズムとBTアルゴリズムも同様の構造を持っています。
それぞれ3組の非結合式の方程式を解く。BTは5x5ブロックのブロック - トリジアゴナルシステムを解決します。
SPは、ほぼ因数分解されたスキームの完全対角化から生じるスカラ五角形システムを解きます。

私たちのモチベーションの例である**BTの分析**は、Wait、Comm_split、およびBarrierがタスクの数とともにかなり大きくなることを示しています。
最も強い相関関係は、Wait：x_solve.f：71です。
図3を参照すると、タスクの数が増えるにつれてこのWaitが一貫して増加していることがわかります。
詳細に検討すると、このWaitはX方向のソルバの最初のIrecvを完了します。
これがシーケンス内の最初のメッセージ渡し操作であるため、その時点までのすべての負荷不均衡がこのWaitに振り込まれます。
他の2つの操作、Comm_splitおよびBarrierは、タスクの数が増えるにつれて増加します。Waitよりも時間がかかるものの、一貫性が低くなっています。したがって、それらは表3においてより低い順位相関を有する。

興味深いことに、**SPの**ランク相関はComm_split、Barrier、およびWaitallをタスクの数と最も正の相関関係に置く。
その構造はBTと非常に似ています。

**NAS CG**は、構造化されていないグリッド計算の特徴である、大規模で疎な対称正定行列の最小固有値への近似を計算します。
私たちのCGの分析では、BarrierといくつかのWaitオペレーションが、スケールの悪い主な犯人と評価されています。
表3および図7に示すように、残りのWaitオペレーションは、タスク数と強い正の相関(positive  correlation with)を示します。
他方、バリアコールは初期化のために使用され、256タスクで1つの実験（図示せず）に対して2つのタスクに対して約1ミリ秒から20秒まで増加する。


#5  CONCLUSIONS
本稿では、スケールの小さい通信operationを識別するための新しい手法を提案し評価した。
本発明の技術は、個々の通信operationのための「時間対全体の通信時間の比」に対するタスク数の非パラメトリック（またはランク）相関を使用する。

最大1024個のプロセッサー上でこれらのアプリケーションを使用した私たちの最初の結果は、我々の相関技法が、あらゆる場合においてスケーリングの悪い操作を自動的かつ正確に特定することを示しています。

また、この技術をASCI Whiteの初期デリバリシステムで1536プロセッサのアプリケーションを分析するのにも、200個以上のMPIコールサイトを使ってアプリケーションを分析することに成功しました。

さらに重要なことに、私たちの技術は、ユーザーがアプリケーションの設計に簡単に関連付けることができるように、パフォーマンスの問題を特定します。

私たちの実験は、私たちの技術が、非常に重要なパフォーマンスデータからトレンドを抽出することを示しましたが、それは明らかではありませんでした。

私たちの実験でも、似ている通信operationは同様に拡張されないことが示されています。
したがって、我々はまた、ロードバランシングの悪さや計算と通信の重複の不備など、他のパフォーマンス現象を堅牢に発見する自動化された手法を検討しています。


